{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Advanced Analytics NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:28:12.472305Z",
     "start_time": "2018-12-04T16:27:10.886061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spark-nlp==1.7.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c1/3ec550fbc22efdcac013a301f74d6c904ec545bef291b414be90d900d1d8/spark_nlp-1.7.3-py2.py3-none-any.whl (72.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 72.8MB 330kB/s eta 0:00:01  3% |█▏                              | 2.6MB 30.3MB/s eta 0:00:03    7% |██▍                             | 5.4MB 29.5MB/s eta 0:00:03    8% |██▊                             | 6.1MB 16.1MB/s eta 0:00:05    13% |████▌                           | 10.1MB 26.7MB/s eta 0:00:03    21% |██████▉                         | 15.6MB 27.3MB/s eta 0:00:03    28% |█████████▏                      | 20.9MB 27.3MB/s eta 0:00:02    32% |██████████▍                     | 23.6MB 27.0MB/s eta 0:00:02    35% |███████████▌                    | 26.1MB 26.9MB/s eta 0:00:02    39% |████████████▋                   | 28.7MB 26.9MB/s eta 0:00:02    42% |█████████████▊                  | 31.2MB 25.1MB/s eta 0:00:02    47% |███████████████▎                | 34.7MB 24.4MB/s eta 0:00:02    49% |███████████████▉                | 36.0MB 24.9MB/s eta 0:00:02    51% |████████████████▎               | 37.1MB 25.8MB/s eta 0:00:02    55% |██████████████████              | 40.7MB 25.3MB/s eta 0:00:02    57% |██████████████████▍             | 41.9MB 24.9MB/s eta 0:00:02    62% |████████████████████            | 45.4MB 24.0MB/s eta 0:00:02    67% |█████████████████████▌          | 48.8MB 24.4MB/s eta 0:00:01    68% |██████████████████████          | 49.9MB 24.1MB/s eta 0:00:01    70% |██████████████████████▍         | 51.0MB 22.8MB/s eta 0:00:01    76% |████████████████████████▎       | 55.3MB 22.8MB/s eta 0:00:01    78% |█████████████████████████▎      | 57.5MB 25.1MB/s eta 0:00:01    80% |█████████████████████████▉      | 58.7MB 24.8MB/s eta 0:00:01    81% |██████████████████████████▎     | 59.7MB 22.5MB/s eta 0:00:01    86% |███████████████████████████▋    | 62.9MB 23.0MB/s eta 0:00:01    89% |████████████████████████████▋   | 65.0MB 22.9MB/s eta 0:00:01    90% |█████████████████████████████   | 66.1MB 20.2MB/s eta 0:00:01    92% |█████████████████████████████▌  | 67.2MB 22.7MB/s eta 0:00:01    95% |██████████████████████████████▌ | 69.3MB 24.9MB/s eta 0:00:01    96% |███████████████████████████████ | 70.4MB 21.1MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: spark-nlp\n",
      "Successfully installed spark-nlp-1.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip install spark-nlp==1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:28:14.748410Z",
     "start_time": "2018-12-04T16:28:14.342555Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a spark context that includes a 3rd party jar for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:28:35.841869Z",
     "start_time": "2018-12-04T16:28:31.934985Z"
    }
   },
   "outputs": [],
   "source": [
    "#jarPath = \"spark-nlp-assembly-1.7.3.jar\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# Todo\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read multiple files in a dir as one Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:28:40.343540Z",
     "start_time": "2018-12-04T16:28:35.844308Z"
    }
   },
   "outputs": [],
   "source": [
    "dataPath = \"./data/reddit/*.json\"\n",
    "df = spark.read.json(dataPath)\n",
    "print(df.count())\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with Struct type to query subfields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:28:40.819564Z",
     "start_time": "2018-12-04T16:28:40.345335Z"
    }
   },
   "outputs": [],
   "source": [
    "title = \"data.title\"\n",
    "author = \"data.author\"\n",
    "\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to implement the equivalent of flatMap in dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:28:43.068755Z",
     "start_time": "2018-12-04T16:28:40.826537Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "dfWordCount = # Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use an NLP libary to do Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:29:10.967990Z",
     "start_time": "2018-12-04T16:28:43.072151Z"
    }
   },
   "outputs": [],
   "source": [
    "from com.johnsnowlabs.nlp.pretrained.pipeline.en import BasicPipeline as bp\n",
    "dfAnnotated = # Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with Map type to query subfields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:29:11.430140Z",
     "start_time": "2018-12-04T16:29:10.973865Z"
    }
   },
   "outputs": [],
   "source": [
    "dfPos = # Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:29:12.012202Z",
     "start_time": "2018-12-04T16:29:11.432322Z"
    }
   },
   "outputs": [],
   "source": [
    "dfPos= # Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only proper nouns NNP or NNPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:29:12.551881Z",
     "start_time": "2018-12-04T16:29:12.014196Z"
    }
   },
   "outputs": [],
   "source": [
    "nnpFilter = \"pos.result = 'NNP' or pos.result = 'NNPS' \"\n",
    "dfNNP = # Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract columns form a map in a col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:29:12.811100Z",
     "start_time": "2018-12-04T16:29:12.556429Z"
    }
   },
   "outputs": [],
   "source": [
    "dfWordTag = # Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "# Todo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "84px",
    "width": "160px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "236px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
